#!/usr/bin/env python -u
# Copyright 2014 James P Goodwin xref utility for the ped editor
import sys
import os
from optparse import OptionParser
import re
from threading import Thread,Lock,RLock
from queue import Queue,Empty
import traceback
from whoosh.index import create_in, open_dir
from whoosh.fields import Schema, ID, TEXT
from whoosh.qparser import QueryParser
import time
import pickle

finish_xref = False
logging_lock = Lock()
meta_db_lock = Lock()
query_lock = Lock()
meta_db = None
xref_count = 0

def xref_log( message, verbose ):
    """ log a message """
    if options.verbose:
        try:
            logging_lock.acquire()
            print(time.ctime(),message)
        finally:
            logging_lock.release()

def is_excluded_file( options, filename ):
    """ test to see if we should exclude this filename """

    filename = os.path.abspath(filename)
    path,ext = os.path.splitext(filename)
    # filter extensions
    if ext.lower() in ['.in','.wsdl','.jpg','.odp','.ods','.xml','.idx','.pdf','.ap_','.zip','.table','.bak','.dex','.gif','.sqlite','.ppt',
        '.db','.apk','.shelve','.svg','.log','.htm','.xcf','.out','.sh','.load','.msc','.so','.doc','.stackdump','.svn-base','.js',
        '.properties','.xls','.json','.pyc','.png','.rss','.sql','.odt','.doc','.a','.css','.wav','.tmp','.lock','.ico','.txt',
        '.html','.lnk',".exe",".dll",".bin",".o",".obj",".class",".swf",".gz",".tar",".tar.gz",".psd",".jar",".zip"]:
        return True

    # and svn paths
    if path.find('.svn') >= 0:
        return True
        
    excludes = options.exclude.split(";")
    for e in excludes:
        if e and re.match(e,filename):
            return True
            
    return False

def xref( options, filename, idx, ix):
    """ add one file to the full text index """
    global xref_count

    xref_log("xref: %d: %s"%(idx,filename), options.verbose)
    
    filename = os.path.abspath(filename)
    remove_file( filename )

    try:
        xref_count += 1
        writer = ix.writer()
        lineno = 0
        pos = 0
        f = open(filename,"rb")
        l = f.readline()
        while l:
            try:
                writer.add_document(path = str(filename), pos = str(str(pos)), line = str(str(lineno)), content = str(l))
            except:
                xref_log("add document error:%s,%d,%s"%(filename,lineno,traceback.format_exc()),options.verbose)
    
            pos = f.tell()
            lineno += 1
            l = f.readline()
        try:
            writer.commit(merge=False)
        except:
            xref_log( "commit error: %s,%s"%(filename,traceback.format_exc()),options.verbose)
    except:
        xref_log( "index init error: %s,%s"%(filename,traceback.format_exc()),options.verbose)
        
    return True
        

def query_idx( query_string, ix ):
    """ run a query against one search index thread body """
    with ix.searcher() as searcher:
        qry = QueryParser("content", ix.schema).parse(query_string)
        res = searcher.search(qry,limit=None)
 
        if res:
            cur_filename = ""
            f = None
            for r in res:
                if r["path"] != cur_filename:
                    cur_filename = r["path"]
                    f = open(cur_filename,"r")
                f.seek(int(r["pos"]))
                text = f.readline().strip()
                try:
                    query_lock.acquire()
                    print(r["line"],"|",r["path"],"|",text)
                finally:
                    query_lock.release()
    
    
def query( query_string, options ):
    """ query the indexes for the query_string """
    query_threads = []
    for si in range(0,options.numthreads):
        index_path = os.path.expanduser("~/.pedxref%02d"%si)
        ix = open_dir(index_path)
        qt = Thread(target=query_idx,args=(query_string,ix))
        qt.start()
        query_threads.append(qt)
        
    for qt in query_threads:
        if qt.isAlive():
            qt.join()
        

def run_xref( q, qi, ix, options ):
    """ run an xref or wait for the queue to produce one """
    global finish_xref
    while True:
        try:
            fn = q.get(True,1)
            q.task_done()   
            fn = os.path.abspath(fn)
            xref( options, fn, qi, ix)
            update_file(fn,qi)
        except Empty:
            if finish_xref:
                return
                
def get_meta_db():
    """ get meta_db """
    global meta_db
    if meta_db == None:
        try:
            meta_db_lock.acquire()
            if meta_db == None:
                if os.path.exists(os.path.expanduser("~/.pedxrefmeta")):
                    meta_db = pickle.load(open(os.path.expanduser("~/.pedxrefmeta"),"rb"))
                else:
                    meta_db = {}
            else:
                return meta_db
        finally:
            meta_db_lock.release()
    return meta_db
    
def update_file( filepath, qi ):
    """ update a file's date in the meta_db """
    get_meta_db()[filepath] = "%f,%d"%(os.stat(filepath).st_mtime,qi)
    
def is_changed_file( filepath ):
    """ return true if file has changed or never been indexed """
    if filepath in get_meta_db():
        ftime = os.stat(filepath).st_mtime
        dbtime = float(get_meta_db()[filepath].split(",",1)[0])
        return ((ftime - dbtime) > 0.5)
    return True
        
def remove_file( filepath ):
    """ remove filepath from the appropriate index """
    if filepath in get_meta_db():
        meta = get_meta_db()[filepath]
        mtime,qi = meta.split(",",1)
        qi = int(qi)
        index_path = os.path.expanduser("~/.pedxref%02d"%qi)
        if os.path.exists(index_path):
            ix = open_dir(index_path)
            writer = ix.writer()
            writer.delete_by_term('path',filepath)
            writer.commit(merge=False)
            ix.close()
                                                             
def get_index( idx ):
    """ open the index number idx and/or create it and return the index object """
    schema = Schema(path=ID(stored=True),line=ID(stored=True),pos=ID(stored=True),content=TEXT(stored=False))
    index_path = os.path.expanduser("~/.pedxref%02d"%idx)
    if not os.path.exists(index_path):
        os.mkdir(index_path)
        ix = create_in(index_path, schema )
    else:
        ix = open_dir(index_path)
    return ix
    

def main( options, args ):
    """ main processing loop for the xref command """
    global finish_xref
    global xref_count
                      
    if options.query:
        query( options.query, options )
        return(0)

    xref_log("Creating queues and starting workers",options.verbose)
    queues = []
    threads = []
    indexes = []
    for qi in range(0,options.numthreads):
        queues.append(Queue())
        indexes.append(get_index(qi))
        
    for qi in range(0,options.numthreads):
        p = Thread(target=run_xref,args=(queues[qi],qi,indexes[qi],options))
        p.start()
        threads.append(p)
    
    xref_log("Adding files to queues",options.verbose)
    
    def enqueue_file( filepath, idx ):
        if not is_excluded_file(options,filepath) and is_changed_file(filepath):
            queues[idx].put(filepath)

    qi = 0
    for f in args:
        enqueue_file(os.path.abspath(f),qi)
        qi = (qi + 1)%options.numthreads
        
    if options.recurse:
        for (dirpath, dirnames, filenames) in os.walk(os.path.expanduser(options.directory)):
            for f in filenames:
                fullpath = os.path.join(dirpath,f)
                if re.search(options.pattern, fullpath):
                    enqueue_file(fullpath,qi)
                    qi = (qi +1)%options.numthreads
                    
    xref_log("Waiting for workers to finish",options.verbose)

    finish_xref = True
    for qi in range(0,options.numthreads):
        if threads[qi].isAlive():
            threads[qi].join()
            
    if xref_count > 1000:
        xref_log("Optimizing indexes",options.verbose)

        for qi in range(0,options.numthreads):
            index_path = os.path.expanduser("~/.pedxref%02d"%qi)
            indexes[qi].optimize()
            indexes[qi].close()
    else:
        for qi in range(0,options.numthreads):
            indexes[qi].close()
            
    if meta_db:
        pickle.dump(meta_db,open(os.path.expanduser("~/.pedxrefmeta"),"wb"),pickle.HIGHEST_PROTOCOL)
    
    xref_log("Done",options.verbose)
    
    return(0)
    
                    

if __name__ == '__main__':
    parser = OptionParser(usage="usage: %prog [options] {files to cross reference}", description="A quick xref for the ped editor")
    parser.add_option("-r","--recurse", dest="recurse", action="store_true", default=False, help="Process directories recursively")
    parser.add_option("-v","--verbose", dest="verbose", action="store_true", default=False, help="Output status while processing")
    parser.add_option("-p","--pattern", dest="pattern", default=".*", help="File pattern to match")
    parser.add_option("-e","--exclude", dest="exclude", default="", help="File path pattern to exclude")
    parser.add_option("-d","--directory", dest="directory", default=".", help="Starting directory")
    parser.add_option("-n","--numthreads", dest="numthreads", type="int", default=10, help="Number of threads to use indexing/querying")
    parser.add_option("-q","--query", dest="query", default="", help="query a name")
    
    (options,args) = parser.parse_args(sys.argv[1:])

    exit(main(options,args))
